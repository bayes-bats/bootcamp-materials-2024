---
title: "Hierarchical Models"
subtitle: "Day 5"
format: 
  revealjs:
    slide-number: true
    incremental: true
    theme: ["../../templates/slides-style.scss"]
    logo: https://www.stat.uci.edu/bayes-bats/img/logo.png
    title-slide-attributes: 
      data-background-image: https://www.stat.uci.edu/bayes-bats/img/logo.png
      data-background-size: 12%
      data-background-position: 50% 85%
---

Note that the example in this lecture is from [Chapter 10.2 of Probability and Bayesian Modeling book](https://bayesball.github.io/BOOK/bayesian-hierarchical-modeling.html#hierarchical-normal-modeling)

# Introduction: Observations in Groups

## Recap: The Normal Model \& Normal Regression

- When you have continuous outcomes, you can use a normal model:
\begin{equation*}
Y_i \mid \mu, \sigma \overset{i.i.d.}{\sim} \textrm{Normal}(\mu, \sigma), \,\,\, i = 1, \cdots, n.
\end{equation*}

- When you have predictor variables available, $\{x_{i1}, \cdots, x_{ip}\}$; you can specify an observation specific mean:
\begin{equation*}
Y_i \mid \mu_i, \sigma \overset{ind}{\sim} \textrm{Normal}(\mu_i, \sigma), \,\,\, i = 1, \cdots, n,
\end{equation*}
where 
\begin{equation*}
\mu_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots, \beta_p x_{ip}.
\end{equation*}
- Observations are assumed independent.

## When Observations Are Not Necessarily Independent

::: nonincremental
- Observations can be dependent in several ways

- Observations are nested in groups:
    - Studentsâ€™ test scores from multiple schools
    - Ratings of movies of different genres
    - Ratings of dramas of different schedules
    - Death rates of hospitals
:::

::: {.callout-warning icon=false}
## Discussion question
Can you think of additional examples of observations in groups?
:::

::: nonincremental
- We will focus on a movie rating dataset to explore modeling approaches for dependent data
:::

# Example: Ratings of Animation Movies

## Ratings of Animation Movies

- Example from [Chapter 10.2 of Probability and Bayesian Modeling book](https://bayesball.github.io/BOOK/bayesian-hierarchical-modeling.html#hierarchical-normal-modeling)

- MovieLens: personalized movie recommendation for users

- In one study, a sample on movie ratings for 8 animation movies released in 2010, total 55 ratings

- Each rating is for a movie completed by a user; some movies have many ratings while others have few

- A natural grouping of these 55 ratings: by movie title

## Plot of Ratings by Title

::: panel-tabset
## Code

```{r, echo = TRUE}
library(tidyverse)

MovieRatings <- read.csv("2010_animation_ratings.csv", header = TRUE, sep = ",")

MovieRatings %>%
  mutate(Title = as.character(title),
         Title = recode(Title,
                  "Shrek Forever After (a.k.a. Shrek: The Final Chapter) (2010)" = "Shrek Forever",
                  "How to Train Your Dragon (2010)" = "Dragon",
                  "Toy Story 3 (2010)" = "Toy Story 3",
                  "Tangled (2010)" = "Tangled",
                  "Despicable Me (2010)" = "Despicable Me",
                  "Legend of the Guardians: The Owls of Ga'Hoole (2010)" = "Guardians",
                  "Megamind (2010)" = "Megamind",
                  "Batman: Under the Red Hood (2010)" = "Batman")) ->
           MovieRatings
```

## Plot
```{r}
ggplot(MovieRatings, aes(Title, rating)) +
  geom_jitter(width = 0.2,
              size = 3) +
  coord_flip() +
  theme_bw(base_size = 15) + 
  ylab("Rating")
```
:::


## Summary Statistics of Ratings by Title

| Movie Title                | Mean |   SD |  N |
| :------------------------- | ---: | ---: | -: |
| Batman: Under the Red Hood | 5.00 |      |  1 |
| Despicable Me              | 3.72 | 0.62 |  9 |
| How to Train Your Dragon   | 3.41 | 0.86 | 11 |
| Legend of the Guardians    | 4.00 |      |  1 |
| Megamind                   | 3.38 | 1.31 |  4 |
| Shrek Forever After        | 4.00 | 1.32 |  3 |
| Tangled                    | 4.20 | 0.89 | 10 |
| Toy Story 3                | 3.81 | 0.96 | 16 |

## Modeling Challenges

- Approach 1 - separate estimates for each movie $j$:
\begin{equation*}
Y_{1j}, \cdots, Y_{n_j j} \overset{i.i.d.}{\sim} \textrm{Normal}(\mu_j, \sigma_j)
\end{equation*}
    - No relation among groups; groups with small sample size might suffer (e.g., $n_j = 1$)

- Approach 2 - combined estimates for all $J$ movies:
\begin{equation*}
Y_{ij} \overset{i.i.d.}{\sim} \textrm{Normal}(\mu, \sigma)
\end{equation*}
    - Differences in groups are ignored

## Potential Solutions

- Something in between - hierarchical/multilevel modeling
    - Pooling information across groups
    - Achieved through a two-stage prior

# A Hierarchical Model with Random $\sigma$

## The Sampling Model

::: nonincremental
- Without loss of generality, assume a group-specific normal model for movie $j$:
\begin{eqnarray}
Y_{ij} \overset{i.i.d.}{\sim} \textrm{Normal}(\mu_j, \sigma)
\end{eqnarray}
where $i = 1, \cdots, n_j$ and $n_j$ is the number of observations in group $j$

- Model parameters: $\{\mu_1, \cdots, \mu_J, \sigma\}$
:::

::: {.callout-warning icon=false}
## Discussion question
Is a commonly shared $\sigma$ reasonable? If not, what can you do?
:::

## A Two-Stage Prior for $\{\mu_1, \cdots, \mu_J\}$: Stage 1

- All movies are animation movies, we could assume that the mean ratings are similar across movies

- First stage: the same normal prior distribution for each mean $\mu_j$
\begin{equation}
\mu_j \mid \mu, \tau \sim \textrm{Normal}(\mu, \tau)
\end{equation}

- This prior allows information pooled across movies (groups)
    - If $\tau$ is large, the $\mu_j$'s are very different a priori $\rightarrow$ modest pooling in parameter estimation
    - If $\tau$ is small, the $\mu_j$'s are very similar a priori $\rightarrow$ large pooling in parameter estimation

- $\mu$ and $\tau$: hyperparameters, and treated random

## A Two-Stage Prior for $\{\mu_1, \cdots, \mu_J\}$: Stage 2

- Second stage: weakly informative hyperpriors for hyperparameters
\begin{eqnarray}
\mu &\sim& \textrm{Normal}(3, 1) \\
\tau &\sim& \textrm{Cauchy}(0, 1)
\end{eqnarray}

- After posterior inference:
    - The posterior of $\mu$ is informative about an average mean rating
    - The posterior of $\tau$ is informative about the variation among the $\mu_j$'s
    
## Prior for $\sigma$ and Graphical Representation

::: columns
::: {.column width="50%"}

::: nonincremental
- Weakly informative prior for $\sigma$:
\begin{eqnarray}
\sigma &\sim& \textrm{Cauchy}(0, 1)
\end{eqnarray}
:::

:::
::: {.column width="50%"}
```{r,  echo = FALSE, out.width = 500}
knitr::include_graphics("treediagram.png")
```
:::
:::

::: {.callout-warning icon=false}
## Discussion question
Describe how the graphical representation corresponds to the hierarchical model. What parameters/hyperparameters are shared among what?
:::


# MCMC Estimation and Diagnostics

## Fitting The Model

::: nonincremental
- Use the `brm()` function with `family = gaussian`

- Use `rating \~ 1 + 1 | Title` expression for model specification
:::

```{r, echo = FALSE}
library(tidyverse)

MovieRatings <- read.csv("2010_animation_ratings.csv", header = TRUE, sep = ",")

MovieRatings %>%
  mutate(Title = as.character(title),
         Title = recode(Title,
                  "Shrek Forever After (a.k.a. Shrek: The Final Chapter) (2010)" = "Shrek Forever",
                  "How to Train Your Dragon (2010)" = "Dragon",
                  "Toy Story 3 (2010)" = "Toy Story 3",
                  "Tangled (2010)" = "Tangled",
                  "Despicable Me (2010)" = "Despicable Me",
                  "Legend of the Guardians: The Owls of Ga'Hoole (2010)" = "Guardians",
                  "Megamind (2010)" = "Megamind",
                  "Batman: Under the Red Hood (2010)" = "Batman")) ->
           MovieRatings
```

```{r, warning = FALSE, message = FALSE, echo = TRUE}
library(brms)
ml_fit <- brm(data = MovieRatings, family = gaussian,
               rating ~ 1 + (1 | Title),
               prior = c(prior(normal(3, 1), class = Intercept),
                         prior(cauchy(0, 1), class = sd),
                         prior(cauchy(0, 1), class = sigma)),
               iter = 20000, warmup = 10000, thin = 10, chains = 2, 
               seed = 1234)
```

## Saving Posterior Draws

::: nonincremental
- Save `post` as a matrix of simulated posterior draws

- The model parameters: $\{\mu, \tau, \mu_1, \cdots, \mu_8, \sigma\}$
:::

```{r, warning = FALSE, message = FALSE, echo = TRUE}
post_ml <- as_draws_df(ml_fit)
print(post_ml)
```


## Posterior Plots

::: nonincremental
- Function `mcmc_areas()` displays a density estimate of the simulated posterior draws with a specified credible interval
:::

```{r fig.height = 2, fig.width = 3, fig.align = "center", echo = TRUE}
library(bayesplot)
mcmc_areas(post_ml, 
           pars = c("b_Intercept", "r_Title[Batman,Intercept]"), 
           prob = 0.95)
```

## Posterior Plots

```{r fig.height = 2, fig.width = 4, fig.align = "center", echo = TRUE}
library(bayesplot)
mcmc_areas(post_ml, 
           pars = c("b_Intercept", 
                    "r_Title[Batman,Intercept]", 
                    "r_Title[Despicable.Me,Intercept]", 
                    "r_Title[Dragon,Intercept]",
                    "r_Title[Guardians,Intercept]",
                    "r_Title[Megamind,Intercept]",
                    "r_Title[Shrek.Forever,Intercept]",
                    "r_Title[Tangled,Intercept]",
                    "r_Title[Toy.Story.3,Intercept]"), 
           prob = 0.95)
```

## Posterior Plots

::: nonincremental
- Between-group variability $\tau$ vs within-group variability $\sigma$
:::

```{r fig.height = 2, fig.width = 3, fig.align = "center", echo = TRUE}
library(bayesplot)
mcmc_areas(post_ml, 
           pars = c("sd_Title__Intercept", "sigma"), 
           prob = 0.95)
```

## MCMC Diagnostics

```{r, eval = FALSE, echo = TRUE}
ml_fit <- brm(data = MovieRatings, family = gaussian,
               rating ~ 1 + (1 | Title),
               prior = c(prior(normal(3, 1), class = Intercept),
                         prior(cauchy(0, 1), class = sd),
                         prior(cauchy(0, 1), class = sigma)),
               iter = 20000, warmup = 10000, thin = 10, chains = 2, 
               seed = 1234)
```

::: nonincremental
- `iter`: total number of iterations
- `warmup`: the number of iterations to be discarded (beginning iterations are not converged)
- `thin`: the number of draws to thin for saving
- `chains`: the number of MCMC chains (some diagnostics can only be done for more than one chain)
:::    
    
## MCMC Diagnostics: Traceplot

::: nonincremental
- Function `mcmc_trace()` displays a traceplot of the simulated posterior draws for each chain
:::

```{r fig.height = 2, fig.width = 3, fig.align = "center"}
mcmc_trace(ml_fit, pars = c("sd_Title__Intercept"))
```

## MCMC Diagnostics: Autocorrelation Plot

::: nonincremental
- Function `mcmc_acf()` displays an autocorrelation plot of the simulated posterior draws
:::

```{r fig.height = 2, fig.width = 3, fig.align = "center"}
mcmc_acf_bar(ml_fit, pars = c("sd_Title__Intercept"))
```

# Additional Bayesian Inferential Questions

## Shrinkage/Pooling Effects

```{r fig.height = 3, fig.width = 3, fig.align = "center", echo = FALSE}
J <- 8
Post_Mus <- post_ml$b_Intercept + 
  post_ml[, 4:11]
Post_Means <- colMeans(Post_Mus)

MovieRatings %>% group_by(Group_Number) %>%
  summarize(Title = first(title),
            N = n(), M = mean(rating),
            SE = sd(rating) / sqrt(N)) -> Ind_Stats

Means1 <- data.frame(Type = "Sample", Mean = Ind_Stats$M)
Means2 <- data.frame(Type = "Posterior", Mean = Post_Means)
Means1$Title <- c("Dragon", "Toy Story 3", "Shrek Forever",
                  "Despicable Me", "Batman", "Guardians",
                  "Megamind", "Tangled")
Means2$Title <- c("Batman", "Despicable Me", "Dragon", "Guardians",
                  "Megamind", "Shrek Forever",
                   "Tangled", "Toy Story 3")
df <- rbind(Means1, Means2)
df$Type <- factor(df$Type, levels = c("Sample", "Posterior"))
ggplot(df,
       aes(Type, Mean, group=Title)) +
  geom_line() + geom_point() +
  annotate(geom = "text",
           x = 0.75,
           y = Means1$Mean + c(0.05, 0, 0.05, 0,
                               0, -0.05, 0, 0),
           size = 2,
           label = Means1$Title) +
  theme_bw()
```

## Sources of Variability

- Two sources of variability in $Y_{ij}$:
\begin{eqnarray*}
Y_{ij} &\overset{i.i.d.}{\sim}& \textrm{Normal}(\mu_j, \sigma) \,\,\, \text{[within-group variability]} \\
\mu_j &\sim& \textrm{Normal}(\mu, \tau) \,\,\, \text{[between-group variability]}
\end{eqnarray*}

- To compare these two sources of variability, one can compute the fraction
\begin{equation*}
R = \frac{\tau^2}{\tau^2 + \sigma^2}
\end{equation*}
from the posterior draws of $\tau$ and $\sigma$

- If $R \rightarrow 1$, the higher the between-group variability

## Sources of Variability: Results

::: panel-tabset
## Code
```{r echo = TRUE}
tau_draws <- post_ml$sd_Title__Intercept
sigma_draws <- post_ml$sigma
R <- tau_draws^2/(tau_draws^2 + sigma_draws^2)
quantile(R, c(0.025, 0.975))
```

## Plot
```{r}
df <- as.data.frame(R)
ggplot(df, aes(x=R)) + 
  geom_density() + 
  labs(title="Density of R") + 
  theme_bw()
```
:::