---
title: "Inference: frequentist vs. Bayesian"
subtitle: "Day 5"
format: 
  revealjs:
    slide-number: true
    incremental: true
    theme: ["../../templates/slides-style.scss"]
    logo: https://www.stat.uci.edu/bayes-bats/img/logo.png
    title-slide-attributes: 
      data-background-image: https://www.stat.uci.edu/bayes-bats/img/logo.png
      data-background-size: 12%
      data-background-position: 50% 95%
    include-after-body: ../../templates/clean_title_page.html
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.align = "center")
options(scipen=0)
library(tidyverse)
library(fivethirtyeight)
library(scales)

theme_set(theme_gray(base_size = 18))


```

## "Statistical inference"

- Hypothesis Testing a la frequentist

- Confidence Intervals

- Hypothesis Testing a la Bayes

- Credible Intervals


## Resources

- Frequentist examples are from [stats4cs.com](https://www.stats4cs.com/)

- Bayesian examples are from [Bayes Rules! Section 8.2](https://www.bayesrulesbook.com/chapter-8.html#posterior-hypothesis-testing)

# Frequentist Inference

## Research Question

Are there any pink cows in the world?


## Hypotheses

**Null** hypothesis: There are __no__ pink cows in the world.  

**Alternative** hypothesis: There is a pink cow in the world.


## Hypothesis Testing Procedure

We go looking for evidence against the null. 

- If we find any evidence against the null (a single pink cow) then we say we **reject the null** hypothesis.

- If we do not find any evidence against the null (a single pink cow) then **we fail to reject the null**. We can keep searching for more evidence against the null (i.e. continue looking for a pink cow). We will never be able to say the null is true so we never accept the null. All we can do is keep looking for a pink cow.



## Research Question

Is there a foreign object in the cat's body?




## Hypothesis Testing

**Null** hypothesis: There is __no__ foreign object in the cat's body.

**Alternative** hypothesis: There  is a foreign object in the cat's body.



## Collect Evidence

X-ray



## Conclusion and Decision


X-ray does not show any foreign object. 


- Fail to reject the null hypothesis.
- We __cannot__ conclude the null hypothesis is true. We __cannot__ accept the null hypothesis.



## Review of Hypothesis Testing

- We assume that the null hypothesis is true.

- We look for evidence against the null.

- If we find any evidence against the null (e.g. a single pink cow) then we can say we **reject the null hypothesis**.

- If we do not find any evidence against the null (a single pink cow) then we fail to reject the null. We can keep searching for more evidence against the null (i.e. continue looking for a pink cow). We will never be able to say the null is true so we never accept the null. We **fail to reject the null**. All we can do is keep looking for a pink cow.

##

We are searching for evidence against the null. 
We are searching for samples that are _significantly_ different than the null.

## Research Question

Do the majority of Americans approve allowing DACA immigrants to become citizens? Survey about this topic can be found [here](https://news.gallup.com/poll/235775/americans-oppose-border-walls-favor-dealing-daca.aspx)


## Hypotheses 

$H_0: \pi = 0.5$  
$H_A: \pi \neq 0.5$


## Assuming Null is True

Recall that according to CLT $p \sim \text{approximately }N(\pi, \frac{\pi(1-\pi)}{n})$

. . .

If $H_0: \pi = 0.5$ then the null sampling distribution would be $N(0.5, \frac{0.5(1-0.5)}{n})$




## Looking for Evidence 


According to a Gallup survey of 1520 US adults , 83% approve of allowing DACA immigrants to become citizens.


. . .

$p = 0.83$  
$n = 1520$

. . .

We said that the null sampling distribution would be $N(0.5, \frac{0.5(1-0.5)}{n})$ which is

$N(0.5, \frac{0.5(1-0.5)}{1520})$

$N(0.5, 0.0001644737)$


## The $H_0$ Sampling Distribution 

```{r}
p <- seq(0.45, 0.55, by = 0.0001)
y <- dnorm(p, mean = 0.5, sd = sqrt(0.5*0.5/1520))
data <- tibble(p = p, y = y)
qplot(p, y, data = data, 
          geom = "line") +
    ylab("") 


```


## What counts as evidence against the null?

Any sample proportion that falls of really far away from the center of the distribution would count as an evidence against the null.

If the null is true, then it would be unlikely to observe extremely high or low sample proportions. 



## Sampling Distribution

```{r}

se <- sqrt(0.5*0.5/1520)
p <- seq(0.1, 0.9, by = 0.0001)
y <- dnorm(p, mean = 0.5, sd = se)
data <- tibble(p = p, y = y)
qplot(p, y, data = data, 
          geom = "line") +
  ylab("") +
    geom_vline(xintercept = 0.83) +
   annotate(geom = "text", x = 0.78, y = 20, label = "p = 0.83")


```


##

We want to know the probability of observing an extreme sample proportion like ours (p = 0.83) if the $H_0$ were true.

. . .

If our sample proportion is "extreme" then so is 0.90, 0.91, 0.917, 0.9273423 etc. 

. . .

Our sample proportion is 0.83 - 0.5 = 0.33 units away from the null.

. . .

So we will consider 0.5 - 0.33 = 0.17 also an "extreme" sample proportion. 

. . .

This makes 0.16, 0.1512, 0.11... also "extreme" 

##

```{r}

se <- sqrt(0.5*0.5/1520)
p <- seq(0.1, 0.9, by = 0.0001)
y <- dnorm(p, mean = 0.5, sd = se)
data <- tibble(p = p, y = y)
qplot(p, y, data = data, 
          geom = "line") +
  ylab("") +
    geom_vline(xintercept = 0.83) +
   annotate(geom = "text", x = 0.78, y = 20, label = "p = 0.83") +
  geom_vline(xintercept = 0.17) + 
  annotate(geom = "text", x = 0.21, y = 20, label = "p = 0.17") 


```

##


If the $H_0$ is true what is the probability that we will observe an extremely high or an extremely low sample proportion?

Probability of observing sample proportion of 0.17 and lower 

. . .

```{r echo = TRUE}
pnorm(0.17, mean = 0.5, sd = 0.01282473)
```

##

Probability of observing sample proportion of 0.83 and higher 

```{r echo=TRUE}
pnorm(0.83, mean = 0.5, sd = 0.01282473, 
      lower.tail = FALSE)
```



## p-value


Adding those up (or you can multiply one of them with 2) we have

```{r echo = TRUE}
pnorm(0.17, mean = 0.5, sd = 0.01282473) + 
  pnorm(0.83, mean = 0.5, sd = 0.01282473, 
        lower.tail = FALSE)
```

. . .

p-value  = $5.188482 \times 10^{-146}$

. . .

P-value is the probability of observing a sample statistic at least as extreme as the one that has been observed if the null hypothesis were true.




## Remembering CLT


```{r fig.height = 4, fig.align='center'}
set.seed(7)

bike_prop <- 0.15

bike <- c(rep("yes", bike_prop*10000), rep("no", (1-bike_prop)*10000))

pop <- tibble(bike)


pop %>% 
  ggplot() +
  aes(x = bike, y = ..prop.., group = 1) +
  geom_bar() +
  labs(title = "Population Distribution")


```

Let $\pi$ represent the proportion of bike owners on campus then $\pi =$ `r bike_prop`. 



## Getting to sampling distribution of single proportion

$p_1$ - Proportion of first sample (n = 100)

```{r}
sample1 <- pop %>% 
  sample_n(100) %>% 
  count(bike) %>% 
  mutate(prop = n/sum(n)) %>% 
  filter(bike == "yes") %>% 
  select(prop) %>% 
  pull()

sample1
```

$p_2$ -Proportion of second sample (n = 100)

```{r}
pop %>% 
  sample_n(100) %>% 
  count(bike) %>% 
  mutate(prop = n/sum(n)) %>% 
  filter(bike == "yes") %>% 
  select(prop) %>% 
  pull()
```

$p_3$ -Proportion of third sample (n = 100)

```{r}
pop %>% 
  sample_n(100) %>% 
  count(bike) %>% 
  mutate(prop = n/sum(n)) %>% 
  filter(bike == "yes") %>% 
  select(prop) %>% 
  pull()
```

```{r cache = TRUE}

sample_props <- vector()


for (i in 1:10000){
 
    sample <- pop %>% 
    sample_n(100) 
    
     sample_props[i] <- min(prop.table(table(sample$bike)))
  
  
  
}

sample_props_data <- tibble(sample_props = sample_props)
```

### Sampling Distribution of Single Proportion

```{r}

sample_props_data %>% 
  ggplot() +
  aes(x = sample_props) +
  geom_histogram(binwidth=0.01) +
  geom_vline(xintercept = bike_prop, color= "#e56646") +
  labs(x = "Sample proportions")
```

##

If certain conditions are met then

$$p \sim \text{approximately } N(\pi, \frac{\pi(1-\pi)}{n})$$


## In Reality

- We only have one sample and thus one point estimate of the population parameter. How can make use of it? 

. . .

- First we will assume the sample proportion is the best thing we have at hand and use it as a point estimate of the population proportion. 

. . .

- Second, even though we embrace the sample proportion as a point estimate of the population proportion, we will need to acknowledge that it has some error. 


## Standard Error


$p \sim  \text{approximately } N(\text{mean} = \pi, \text{sd} = \sqrt{\frac{\pi(1-\pi)}{n}})$

. . .

We call the standard deviation of the sampling distribution __standard error__ of the estimate. 

Standard error of single proportion is $\sqrt{\frac{p(1-p)}{n}}$.



## Confidence Interval 

CI = $\text{point estimate} \pm \text { margin of error}$

. . .

CI = $\text{point estimate} \pm \text { critical value} \times \text{standard error}$

. . .

CI for single proportion = $p \pm \text {critical value} \times \text{standard error}$

. . .

CI for single proportion = $p \pm \text {critical value} \times \sqrt{\frac{p(1-p)}{n}}$

. . .

95% CI for single proportion = $p \pm 1.96 \times \sqrt{\frac{p(1-p)}{n}}$ because ...

##

95% of the data falls within 1.96 standard deviations in the normal distribution.
      
```{r}

z <- seq(-4, 4, by = 0.01)
y <- dnorm(z)
data <- tibble(z = z, y = y)
qplot(z, y, data = data, 
          geom = "line") +
  geom_ribbon(data = subset(data, z > -1.96 & z <1.96),
                  aes(ymax = y), 
                  ymin = 0,
                  fill = "#e56646", 
                  colour = NA, 
                  alpha = 0.5) +
  ylab("") +
  scale_x_continuous(breaks = c(-1.96,0,1.96)) +
  annotate(geom = "text", x = 0, y = 0.15, label = "95%") +
  annotate(geom = "text", x = 2.3, y = 0.01, label = "2.5%") +
  annotate(geom = "text", x = - 2.3, y = 0.01, label = "2.5%")

  
```
      

## How do we know that?

```{r echo = TRUE}
qnorm(0.025, mean = 0 , sd = 1)
```

```{r echo = TRUE}
qnorm(0.975, mean = 0 , sd = 1)
```


## 95% CI for the first sample

Recall $p = 0.17$ and $n = 100$

. . .

95% CI for single proportion = $p \pm 1.96 \times \sqrt{\frac{p(1-p)}{n}}$ 

. . .

95% CI = $0.17 \pm 1.96 \times \sqrt{\frac{0.17(1-0.17)}{100}}$ 

. . .

95% CI = $0.17 \pm 1.96 \times 0.03756328$ 

. . .

95%CI = $0.17 \pm 0.07362403$

. . .

95%CI = (0.09637597, 0.243624)



## 95% CI for the first sample

95%CI = (0.09637597, 0.243624)

We are 95% confident that the true population proportion of bike owners is in this confidence interval.

class: middle center

95%CI = (0.09637597, 0.243624)


```{r}
tibble(p = bike_prop, n = 1, lower_bound = 0.09637597, upper_bound = 0.243624) %>% 
  ggplot() +
  aes(x = p, y = n) +
  geom_point() +
  geom_errorbarh(aes(xmin = lower_bound, xmax = upper_bound, height = .01)) +
  labs(y = " ",
       x = " ") +
  theme(axis.text.y = element_blank()) 
```


## Understanding Confidence Intervals


I have taken 100 samples with $n = 100$, calculated the sample proportion, standard error, and 95% CI interval for each sample

```{r}
set.seed(26)

cv <- qnorm(0.025)

ci_data <- sample_props_data %>% 
  sample_n(100) %>% 
  rename(p = sample_props) %>% 
  mutate(SE = sqrt((p*(1-p))/100),
         lower_bound = p + (cv*SE),
         upper_bound = p  - (cv*SE))


ci_data
```


## Understanding Confidence Intervals

```{r}
ci_data <-
  ci_data %>% 
  mutate(n = 1:nrow(ci_data)) %>% 
  mutate(contains = ifelse(lower_bound < bike_prop & upper_bound > bike_prop , 1,0)) 
```


```{r}
ci_data %>% 
  ggplot() +
  aes(x = p, y = n) +
  geom_point() +
  geom_errorbarh(aes(xmin = lower_bound, xmax = upper_bound)) +
  labs(y = " ") +
  theme(axis.text.y = element_blank()) 
```


## Understanding Confidence Intervals


```{r}
ci_data %>% 
  ggplot() +
  aes(x = p, y = n, color = as.factor(contains)) +
  geom_point() +
  geom_errorbarh(aes(xmin = lower_bound, xmax = upper_bound)) +
  labs(y = " ") +
  theme(axis.text.y = element_blank(),
        legend.position = "none")  +
  geom_vline(xintercept =  bike_prop, color= "#e56646") 
  
```


##

- The confidence interval can be expressed in terms of a long-run frequency in repeated samples (or in resampling): "Were this procedure to be repeated on numerous samples, the proportion of calculated 95% confidence intervals that encompassed the true value of the population parameter would tend toward 95%."

- The confidence interval can be expressed in terms of probability with respect to a single theoretical (yet to be realized) sample: "There is a 95% probability that the 95% confidence interval calculated from a given future sample will cover the true value of the population parameter."
This essentially reframes the "repeated samples" interpretation as a probability rather than a frequency.

- The confidence interval can be expressed in terms of statistical significance, e.g.: "The 95% confidence interval represents values that are not statistically significantly different from the point estimate at the .05 level."

# Bayesian Inference 

##

```{r}
#| echo: true
library(bayesrules)
data(moma_sample)
glimpse(moma_sample)
```

$$Y|\pi  \sim \text{Bin}(100, \pi)$$ 

$$\pi  \sim \text{Beta}(4, 6)$$

##

```{r}
#| echo: true
moma_sample %>% 
  mutate(genx = (birth >= 1965)) %>% 
  janitor::tabyl(genx)
```

##

$$\begin{split}
Y | \pi & \sim \text{Bin}(100, \pi) \\
\pi & \sim \text{Beta}(4, 6) \\
\end{split} \;\;\;\; \Rightarrow \;\;\;\; \pi | (Y = 14) \sim \text{Beta}(18, 92)$$

##

```{r fig.height=5, fig.width=9}
#| echo: true
plot_beta_binomial(alpha = 4, beta = 6, y = 14, n = 100)
```

##

```{r echo=FALSE, fig.width=12}
# Keep: these references are woven throughout the discussion

# Data
y <- 14
n <- 100

# Prior parameters
prior_a <- 4
prior_b <- 6

# Posterior parameters
post_a <- prior_a + y
post_b <- prior_b + n - y

# Posterior trend
post_mean_unrounded <- round(post_a / (post_a + post_b),3)
post_mean <- round(post_mean_unrounded, 2)
post_mode <- round((post_a - 1) / (post_a + post_b - 2), 2)

# 95% CI
qs <- qbeta(c(0.025, 0.975), post_a, post_b)
lower_95 <- round(qs[1],2)
upper_95 <- round(qs[2],2)

# 99% CI
qs <- qbeta(c(0.005, 0.995), post_a, post_b)
lower_99 <- round(qs[1],2)
upper_99 <- round(qs[2],2)

# Probabilities
post_prob <- pbeta(0.20, post_a, post_b)
prior_prob <- pbeta(0.20, prior_a, prior_b)
new_y <- 0
new_n <- 10
new_post_a <- prior_a + new_y
new_post_b <- prior_b + new_n - new_y
qs <- qbeta(c(0.025, 0.975), new_post_a, new_post_b)
new_lower_95 <- round(qs[1],2)
new_upper_95 <- round(qs[2],2)

plot_fun <- function(a,b,x,n,level){
  q1  <- (1 - level)/2
  q2  <- 1 - q1
  p_a <- a + x
  p_b <- b + n - x
  ci  <- qbeta(c(q1,q2), p_a, p_b)
  post_mode <- (p_a - 1) / (p_a + p_b - 2)
  marks <- c(ci, post_mode)
  ggplot(data.frame(x = c(0.4,1)), aes(x=x)) + 
    stat_function(fun = dbeta, args = list(p_a, p_b), xlim = ci, geom = "area", fill = "lightblue") + 
    stat_function(fun = dbeta, args = list(p_a, p_b)) + 
    geom_segment(data = data.frame(x = marks, y1 = c(0,0,0), y2 = dbeta(marks, p_a, p_b)),
                 aes(x = x, xend = x, y = y1, yend = y2)) +
    labs(x = expression(pi), y = "density") + 
    lims(y = c(0,12), x = c(0,0.6))
}

plot_fun(4, 4, y, n, level = 0.95) +
  labs(y = expression(paste("f(",pi,"|Y=14)")))
```

##

```{r}
#| echo: true
summarize_beta_binomial(4, 6, y = 14, n = 100)
```

##

## 95% Posterior Credible Interval (CI)

0.025th & 0.975th quantiles of the Beta(18,92) posterior

```{r}
#| echo: true
qbeta(c(0.025, 0.975), 18, 92)
```

. . .

$\int_{0.1}^{0.24} f(\pi|(y=14)) d\pi  \; \approx \; 0.95$

##

```{r post-ci-ch8, fig.width = 10, echo = FALSE, message=FALSE}
# Alt text: The same roughly symmetric density curve, which ranges from roughly 0.05 to 0.3 is plotted three times. In the left curve, a narrow area between 0.14 and 0.19 is shaded in. In the middle curve, a wider area between 0.1 and 0.24 is shaded in. In the right curve, the widest area between 0.08 and 0.26 is shaded in.
g1 <- plot_fun(prior_a, prior_b, y, n, level = 0.50) + lims(x = c(0,0.32)) +
  labs(title = "50% posterior CI")
g2 <- plot_fun(prior_a, prior_b, y, n, level = 0.95) + lims(x = c(0,0.32)) +
  labs(title = "95% posterior CI")
g3 <- plot_fun(prior_a, prior_b, y, n, level = 0.99) + lims(x = c(0,0.32)) +
  labs(title = "99% posterior CI")
gridExtra::grid.arrange(g1,g2,g3,ncol=3)
```

##

$$\begin{split}
H_0: & \; \; \pi \ge 0.20 \\
H_a: & \; \; \pi < 0.20 \\
\end{split}$$

##


```{r post-prob-ch8, echo = FALSE}
plot_prob_plot <- function(a,b,cutoff){
  ggplot(data.frame(x = c(0,1)), aes(x=x)) + 
    stat_function(fun = dbeta, args = list(a, b), xlim = c(0,cutoff), geom = "area", fill = "lightblue") + 
    stat_function(fun = dbeta, args = list(a, b)) + 
    geom_segment(aes(x = cutoff, xend = cutoff, y = 0, yend = dbeta(cutoff, a, b))) +
    labs(x = expression(pi), y = "density")
}

plot_prob_plot(post_a, post_b, cutoff = 0.20) + 
  lims(y = c(0,12.5), x = c(0, 0.32))
```

##


```{r}
#| echo: true
# Posterior probability that pi < 0.20
post_prob <- pbeta(0.20, 18, 92)
post_prob
```

##

$$\text{Posterior odds } = \frac{P(H_a \; | \; (Y=14))}{P(H_0 \; | \; (Y=14))} \approx 5.62 $$  

. . .

```{r}
#| echo: true
# Posterior odds
post_odds <- post_prob / (1 - post_prob)
post_odds
```

##


```{r prior-post-ch8, echo = FALSE, fig.width = 10}
g1 <-plot_prob_plot(prior_a, prior_b, cutoff = 0.20) + 
  lims(y = c(0,12.5)) + 
  labs(title = "Prior")

g2 <- plot_prob_plot(post_a, post_b, cutoff = 0.20) + 
  lims(y = c(0,12.5)) + 
  labs(title = "Posterior")

gridExtra::grid.arrange(g1, g2, ncol = 2)

```

##

$$P(\pi<0.20)$$

```{r}
#| echo: true
prior_prob <- pbeta(0.20, 4, 6)
prior_prob
```

. . .

$$\text{Prior odds } = \frac{P(H_a)}{P(H_0)} \approx 0.093 \; .$$ 

```{r}
#| echo: true
prior_odds <- prior_prob / (1 - prior_prob)
prior_odds
```

##


The __Bayes Factor (BF)__ compares the posterior odds to the prior odds, hence provides insight into just how much our understanding about Gen X representation _evolved_ upon observing our sample data:


$$\text{Bayes Factor} = \frac{\text{Posterior odds }}{\text{Prior odds }}$$

```{r echo = FALSE}
BF <- post_odds / prior_odds
```


## Bayes Factor

In a hypothesis test of two competing hypotheses, $H_a$ vs $H_0$, the Bayes Factor is an odds ratio for $H_a$:

$$\text{Bayes Factor}
= \frac{\text{Posterior odds}}{\text{Prior odds}}
= \frac{P(H_a | Y) / P(H_0 | Y)}{P(H_a) / P(H_0)}
 \; .$$

As a ratio, it's meaningful to compare the Bayes Factor (BF)\ to 1.  To this end, consider three possible scenarios:

1. BF = 1:  The plausibility of $H_a$ _didn't change_ in light of the observed data.
2. BF > 1:  The plausibility of $H_a$ _increased_ in light of the observed data.  Thus the greater the Bayes Factor, the more convincing the evidence for $H_a$.
3. BF < 1:  The plausibility of $H_a$ _decreased_ in light of the observed data. 


## Two-sided Tests

$$\begin{split}
H_0: & \; \; \pi = 0.3 \\
H_a: & \; \; \pi \ne 0.3 \\
\end{split}$$

$$\text{Posterior odds } = \frac{P(H_a \; | \; (Y=14))}{P(H_0 \; | \; (Y=14))} = \frac{1}{0} = \text{ nooooo!}$$

. . .

Recall 95% posterior CI

```{r}
qbeta(c(0.025, 0.975), 18, 92)
```

. . .

##

```{r cache=TRUE, message=FALSE}
library(rstan)
# STEP 1: DEFINE the model
art_model <- "
  data {
    int<lower=0, upper=100> Y;
  }
  parameters {
    real<lower=0, upper=1> pi;
  }
  model {
    Y ~ binomial(100, pi);
    pi ~ beta(4, 6);
  }
"
# STEP 2: SIMULATE the posterior
art_sim <- stan(model_code = art_model, data = list(Y = 14), 
  chains = 4, iter = 5000*2, seed = 84735)
```



```{r message=FALSE, fig.height=5}
#| echo: true
library(bayesplot)
# Parallel trace plots & density plots
mcmc_trace(art_sim, pars = "pi", size = 0.5)
```

##


```{r message=FALSE}
# Combined density plot
mcmc_dens_overlay(art_sim, pars = "pi")
```

##

```{r message=FALSE}
# Combined density plot
mcmc_dens(art_sim, pars = "pi")
```

##

```{r eval=FALSE}
summary(art_sim, pars = "pi")
```

##


```{r}
mcmc_areas(art_sim, pars = "pi",
  prob = 0.95, point_est = "mean")
```

## 


```{r}
mcmc_areas(art_sim, pars = "pi",
  prob = 0.95, point_est = "mean")
```

##

```{r}
art_chains_df <- as.data.frame(art_sim, 
  pars ="lp__", include = FALSE)

art_chains_df %>% 
  summarize(post_mean = mean(pi), 
    post_mode = sample_mode(pi),
    lower_95 = quantile(pi, 0.025),
    upper_95 = quantile(pi, 0.975))
```

##


```{r}
art_chains_df %>% 
  mutate(exceeds = pi < 0.20) %>% 
  janitor::tabyl(exceeds)
```

. . .

```{r}
post_prob
```


__a Bayesian analysis assesses the uncertainty regarding an unknown parameter $\pi$ in light of observed data $Y$__.


$$P((\pi < 0.20) \; | \; (Y = 14)) = `r post_prob` \;.$$

. . .

__a frequentist analysis assesses the uncertainty of the observed data $Y$ in light of assumed values of $\pi$.__

$$P((Y \le 14) | (\pi = 0.20)) = 0.08$$


